# pages/99_ç”»åƒãƒ­ã‚°é›†è¨ˆ.py
# ============================================================
# ğŸ“Š ç”»åƒç”Ÿæˆ/ä¿®æ­£ãƒ­ã‚° é›†è¨ˆãƒ“ãƒ¥ãƒ¼ã‚¢ï¼ˆç®¡ç†è€…å°‚ç”¨ï¼‰
# ============================================================

from __future__ import annotations
from pathlib import Path
import json
import datetime as dt
from typing import List, Dict, Any

import streamlit as st
import pandas as pd

# --- add this at the very top BEFORE importing common_lib ---
import sys
from pathlib import Path

def _add_commonlib_parent_to_syspath():
    here = Path(__file__).resolve()
    # è‡ªåˆ†ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¸Šæ–¹å‘ã«è¾¿ã£ã¦ common_lib ãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¢ã™
    for parent in [here.parent, *here.parents]:
        for name in ("common_lib", "COMMON_LIB"):
            if (parent / name).is_dir():
                if str(parent) not in sys.path:
                    sys.path.insert(0, str(parent))  # è¦ªã‚’è¿½åŠ ï¼ˆè¦ª/ common_lib ãŒ import å¯¾è±¡ã«ãªã‚‹ï¼‰
                return str(parent)
    return None

_add_commonlib_parent_to_syspath()
# --- then your original imports ---
from common_lib.auth.auth_helpers import get_current_user_from_session_or_cookie, is_admin



# ============================================================
# ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡
# ============================================================
user, payload = get_current_user_from_session_or_cookie(st)

st.set_page_config(page_title="ç”»åƒãƒ­ã‚°é›†è¨ˆï¼ˆç®¡ç†è€…å°‚ç”¨ï¼‰", page_icon="ğŸ“Š", layout="wide")


#
# ãƒ‡ãƒãƒƒã‚°ç”¨
#

from common_lib.auth.auth_helpers import (
    _resolve_settings_path, get_admin_users, clear_auth_caches
)

clear_auth_caches()  # â† å¿µã®ãŸã‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤
# st.write("ğŸª¶ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ¢ç´¢çµæœ:", _resolve_settings_path())
# st.write("ğŸª¶ ç®¡ç†è€…ä¸€è¦§:", sorted(get_admin_users()))
st.write("ğŸª¶ ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼:", user)



if not user:
    st.warning("æœªãƒ­ã‚°ã‚¤ãƒ³ã§ã™ã€‚ã‚µã‚¤ãƒ³ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

if not is_admin(user):
    st.error("ğŸš« ã“ã®ãƒšãƒ¼ã‚¸ã¯ç®¡ç†è€…ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚")
    st.stop()



# ============================================================
# åŸºæœ¬è¨­å®š
# ============================================================
st.title("ğŸ“Š ç”»åƒç”Ÿæˆ/ä¿®æ­£ ãƒ­ã‚°é›†è¨ˆï¼ˆç®¡ç†è€…å°‚ç”¨ï¼‰")

APP_DIR = Path(__file__).resolve().parents[1]
APP_NAME = APP_DIR.name
# â˜… ã“ã“ã‚’å¤‰æ›´ï¼šå…±é€šãƒ­ã‚¬ãƒ¼ã®å‡ºåŠ›è¦ç´„ï¼ˆlogs/{app_name}.log.jsonlï¼‰ã«åˆã‚ã›ã‚‹
LOG_FILE = (APP_DIR / "logs" / f"{APP_NAME}.log.jsonl").resolve()

JST = dt.timezone(dt.timedelta(hours=9), name="Asia/Tokyo")


# ============================================================
# ãƒ­ã‚°èª­è¾¼
# ============================================================
@st.cache_data(show_spinner=False)
def load_logs(path: Path) -> pd.DataFrame:
    if not path.exists():
        return pd.DataFrame()

    rows: List[Dict[str, Any]] = []
    with path.open("r", encoding="utf-8") as f:
        for line in f:
            try:
                rows.append(json.loads(line.strip()))
            except Exception:
                continue

    df = pd.DataFrame(rows)
    if "ts" in df.columns:
        ts = pd.to_datetime(df["ts"], utc=True, errors="coerce")
        df["ts"] = ts.dt.tz_convert("Asia/Tokyo")
        df["date"] = df["ts"].dt.date
        df["month"] = df["ts"].dt.strftime("%Y-%m")
    else:
        df["ts"] = pd.NaT
        df["date"] = pd.NaT
        df["month"] = None

    df["user"] = df.get("user", "(anonymous)").fillna("(anonymous)")
    return df


df = load_logs(LOG_FILE)


# ============================================================
# ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
# ============================================================
with st.expander("ğŸ“ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±", expanded=False):
    st.write(f"**Path:** `{LOG_FILE}`")
    if LOG_FILE.exists():
        mtime = dt.datetime.fromtimestamp(LOG_FILE.stat().st_mtime, tz=JST)
        st.write(f"**æœ€çµ‚æ›´æ–°:** {mtime:%Y-%m-%d %H:%M:%S %Z}")
        st.write(f"**è¡Œæ•°:** {len(df):,}")
    else:
        st.warning("ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        st.stop()

if df.empty:
    st.warning("ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()


# ============================================================
# ãƒ•ã‚£ãƒ«ã‚¿
# ============================================================
st.divider()
st.subheader("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿")

c1, c2, c3 = st.columns([1, 1, 2])
min_date, max_date = df["date"].min(), df["date"].max()

with c1:
    date_from = st.date_input("é–‹å§‹æ—¥", value=min_date or dt.date.today())
with c2:
    date_to = st.date_input("çµ‚äº†æ—¥", value=max_date or dt.date.today())
with c3:
    users = sorted(df["user"].dropna().unique().tolist())
    picked_users = st.multiselect("ãƒ¦ãƒ¼ã‚¶ãƒ¼é¸æŠ", options=users, default=users)

mask = (df["date"] >= date_from) & (df["date"] <= date_to)
mask &= df["user"].isin(picked_users)
fdf = df[mask].copy()

st.caption(f"å¯¾è±¡ãƒ¬ã‚³ãƒ¼ãƒ‰: **{len(fdf):,} / {len(df):,}**")


# ============================================================
# ã‚µãƒãƒªãƒ¡ãƒˆãƒªã‚¯ã‚¹
# ============================================================
gen_cnt = (fdf["action"] == "generate").sum()
edit_cnt = (fdf["action"] == "edit").sum()
unique_users = fdf["user"].nunique()

m1, m2, m3 = st.columns(3)
m1.metric("ä½œæˆï¼ˆgenerateï¼‰", f"{gen_cnt:,}")
m2.metric("æ”¹ä¿®ï¼ˆeditï¼‰", f"{edit_cnt:,}")
m3.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼", f"{unique_users:,}")


# ============================================================
# ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ é›†è¨ˆ
# ============================================================
st.divider()
st.subheader("ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥ é›†è¨ˆ")

user_pivot = (
    fdf[fdf["action"].isin(["generate", "edit"])]
    .pivot_table(index="user", columns="action", values="ts", aggfunc="count", fill_value=0)
    .reset_index()
)

for col in ["generate", "edit"]:
    if col not in user_pivot.columns:
        user_pivot[col] = 0

user_pivot["total"] = user_pivot["generate"] + user_pivot["edit"]
user_pivot = user_pivot.sort_values("total", ascending=False)

st.dataframe(user_pivot, width="stretch")
st.download_button(
    "â¬‡ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥é›†è¨ˆ CSV",
    data=user_pivot.to_csv(index=False).encode("utf-8-sig"),
    file_name="user_summary.csv",
    mime="text/csv",
)

# ============================================================
# æœˆåˆ¥ é›†è¨ˆ
# ============================================================
st.divider()
st.subheader("ğŸ—“ï¸ æœˆåˆ¥ é›†è¨ˆ")

monthly = (
    fdf[fdf["action"].isin(["generate", "edit"])]
    .groupby(["month", "action"])["ts"]
    .count()
    .unstack(fill_value=0)
    .reset_index()
)

for col in ["generate", "edit"]:
    if col not in monthly.columns:
        monthly[col] = 0

monthly["total"] = monthly["generate"] + monthly["edit"]
monthly = monthly.sort_values("month")

st.dataframe(monthly, width="stretch")
st.bar_chart(monthly.set_index("month")[["generate", "edit"]])

st.download_button(
    "â¬‡ï¸ æœˆåˆ¥é›†è¨ˆ CSV",
    data=monthly.to_csv(index=False).encode("utf-8-sig"),
    file_name="monthly_summary.csv",
    mime="text/csv",
)



# ============================================================
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ Ã— æœˆåˆ¥ é›†è¨ˆï¼ˆåˆè¨ˆ / generate / editï¼‰
# ============================================================
st.divider()
st.subheader("ğŸ‘¥ğŸ—“ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ Ã— æœˆåˆ¥ é›†è¨ˆ")

# å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ï¼ˆgenerate / edit ã®ã¿ï¼‰
df_um = fdf[fdf["action"].isin(["generate", "edit"])].copy()
if df_um.empty:
    st.info("å¯¾è±¡æœŸé–“ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è©²å½“ã™ã‚‹ãƒ­ã‚°ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    # æœˆã®ä¸¦ã³é †ã‚’å›ºå®šï¼ˆæ¬ ææœˆã‚‚0ã§åŸ‹ã‚ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ï¼‰
    months = sorted(df_um["month"].dropna().unique().tolist())
    df_um["month"] = pd.Categorical(df_um["month"], categories=months, ordered=True)

    # åˆè¨ˆï¼ˆgenerate + editï¼‰
    pivot_total = (
        df_um
        .groupby(["user", "month"])
        .size()
        .unstack(fill_value=0)
        .reindex(columns=months, fill_value=0)
        .sort_index()
    )

    # å€‹åˆ¥ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    def pivot_for(action: str) -> pd.DataFrame:
        _tmp = (
            df_um[df_um["action"] == action]
            .groupby(["user", "month"])
            .size()
            .unstack(fill_value=0)
            .reindex(columns=months, fill_value=0)
            .sort_index()
        )
        # å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»å…¨æœˆã«0ã§æƒãˆã‚‹
        return _tmp.reindex(index=sorted(df_um["user"].unique()), fill_value=0)

    pivot_gen  = pivot_for("generate")
    pivot_edit = pivot_for("edit")

    tab_total, tab_gen, tab_edit, tab_chart = st.tabs(["åˆè¨ˆ", "generate", "edit", "ãƒãƒ£ãƒ¼ãƒˆ"])

    with tab_total:
        st.caption("ãƒ¦ãƒ¼ã‚¶ãƒ¼ Ã— æœˆ åˆ—ï¼šæœˆ / å€¤ï¼šä»¶æ•°ï¼ˆgenerate + editï¼‰")
        st.dataframe(pivot_total, width="stretch")
        st.download_button(
            "â¬‡ï¸ åˆè¨ˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼Ã—æœˆï¼‰CSV",
            data=pivot_total.to_csv(index=True).encode("utf-8-sig"),
            file_name="user_by_month_total.csv",
            mime="text/csv",
        )

    with tab_gen:
        st.caption("ãƒ¦ãƒ¼ã‚¶ãƒ¼ Ã— æœˆ åˆ—ï¼šæœˆ / å€¤ï¼šä»¶æ•°ï¼ˆgenerateï¼‰")
        st.dataframe(pivot_gen, width="stretch")
        st.download_button(
            "â¬‡ï¸ generateï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼Ã—æœˆï¼‰CSV",
            data=pivot_gen.to_csv(index=True).encode("utf-8-sig"),
            file_name="user_by_month_generate.csv",
            mime="text/csv",
        )

    with tab_edit:
        st.caption("ãƒ¦ãƒ¼ã‚¶ãƒ¼ Ã— æœˆ åˆ—ï¼šæœˆ / å€¤ï¼šä»¶æ•°ï¼ˆeditï¼‰")
        st.dataframe(pivot_edit, width="stretch")
        st.download_button(
            "â¬‡ï¸ editï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼Ã—æœˆï¼‰CSV",
            data=pivot_edit.to_csv(index=True).encode("utf-8-sig"),
            file_name="user_by_month_edit.csv",
            mime="text/csv",
        )

    with tab_chart:
        st.caption("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’é¸ã¶ã¨æœˆæ¬¡æ¨ç§»ã‚’è¡¨ç¤ºï¼ˆåˆè¨ˆ / å†…è¨³ã‚’åˆ‡æ›¿å¯ï¼‰")
        chart_kind = st.radio("ç³»åˆ—", ["åˆè¨ˆ", "generate", "edit"], horizontal=True)
        pick_users = st.multiselect(
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰",
            options=sorted(pivot_total.index.tolist()),
            default=sorted(pivot_total.index.tolist())[:5],
        )

        if chart_kind == "åˆè¨ˆ":
            df_plot = pivot_total
        elif chart_kind == "generate":
            df_plot = pivot_gen
        else:
            df_plot = pivot_edit

        df_plot = df_plot.loc[df_plot.index.intersection(pick_users)]
        if df_plot.empty:
            st.info("è¡¨ç¤ºå¯¾è±¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            # æœˆã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è»¢ç½®ã—ã¦å¯è¦–åŒ–ï¼ˆç¸¦ï¼šæœˆã€æ¨ªï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¤‡æ•°ç³»åˆ—ï¼‰
            st.bar_chart(df_plot.T)

# ============================================================
# ğŸ§¹ å¹´æœˆã§ãƒ­ã‚°å‰Šé™¤ï¼ˆJSONLã‚’ç‰©ç†å‰Šé™¤ï¼‰
# ============================================================
st.divider()
st.subheader("ğŸ§¹ å¹´æœˆã§ãƒ­ã‚°å‰Šé™¤")

# åˆ©ç”¨å¯èƒ½ãªå¹´æœˆãƒªã‚¹ãƒˆï¼ˆYYYY-MMï¼‰
all_months = sorted(df["month"].dropna().unique().tolist())
sel_months = st.multiselect(
    "å‰Šé™¤ã™ã‚‹å¹´æœˆï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰", options=all_months,
    help="é¸ã‚“ã å¹´æœˆã«å±ã™ã‚‹è¡Œï¼ˆgenerate / edit ãªã©å…¨ã‚¤ãƒ™ãƒ³ãƒˆï¼‰ã‚’ç‰©ç†å‰Šé™¤ã—ã¾ã™ã€‚å…ƒã«æˆ»ã›ãªã„ãŸã‚æ³¨æ„ã€‚"
)

# å®‰å…¨ãªåŸå­çš„æ›¸ãæ›ãˆ
def _atomic_write_jsonl(path: Path, records: list[dict]) -> None:
    tmp = path.with_suffix(path.suffix + ".tmp")
    with tmp.open("w", encoding="utf-8") as f:
        for r in records:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")
    tmp.replace(path)

if sel_months:
    # å‰Šé™¤è¦‹è¾¼ã¿ä»¶æ•°ï¼ˆå…¨ä½“ df ãƒ™ãƒ¼ã‚¹ï¼‰
    to_delete_count = int(df[df["month"].isin(sel_months)].shape[0])
    st.warning(f"å‰Šé™¤å¯¾è±¡: **{to_delete_count:,} è¡Œ**ï¼ˆ{', '.join(sel_months)}ï¼‰")

    # æœ€çµ‚ç¢ºèª
    confirm = st.text_input("ç¢ºèªã®ãŸã‚ DELETE ã¨å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="DELETE")

    # å®Ÿè¡Œãƒœã‚¿ãƒ³
    do_purge = st.button("é¸æŠã—ãŸå¹´æœˆã®ãƒ­ã‚°ã‚’å‰Šé™¤ã™ã‚‹", type="secondary", disabled=(to_delete_count == 0))
    if do_purge:
        if confirm != "DELETE":
            st.error("ç¢ºèªæ–‡å­—åˆ—ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚DELETE ã¨å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif not LOG_FILE.exists():
            st.error("ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        else:
            # 1) å…¨è¡Œã‚’èª­ã¿ã€tsâ†’YYYY-MM ã‚’ç®—å‡ºã—ã¦ãƒ•ã‚£ãƒ«ã‚¿
            original: list[dict] = []
            kept: list[dict] = []
            with LOG_FILE.open("r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        rec = json.loads(line)
                    except Exception:
                        # èª­ã‚ãªã„è¡Œã¯æ¸©å­˜ï¼ˆå®‰å…¨å´ï¼‰
                        kept.append({"_raw": line})
                        continue

                    original.append(rec)
                    ts = rec.get("ts")
                    month = None
                    if ts:
                        try:
                            # ts ã‹ã‚‰ JST ã§ YYYY-MM ã‚’ç®—å‡º
                            month = pd.to_datetime(ts, utc=True, errors="coerce").tz_convert("Asia/Tokyo").strftime("%Y-%m")
                        except Exception:
                            month = None

                    if month not in sel_months:
                        kept.append(rec)

            removed = len(original) - (len([r for r in kept if isinstance(r, dict)]))
            # 2) ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            try:
                backup = LOG_FILE.with_suffix(".jsonl.bak")  # ä¾‹: *.log.jsonl.bak
                backup.write_text(LOG_FILE.read_text(encoding="utf-8"), encoding="utf-8")
            except Exception as e:
                st.error(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.stop()

            # 3) åŸå­çš„ã«æ›¸ãæ›ãˆ
            try:
                tmp = LOG_FILE.with_suffix(LOG_FILE.suffix + ".tmp")
                with tmp.open("w", encoding="utf-8") as wf:
                    for r in kept:
                        if isinstance(r, dict) and "_raw" in r:
                            wf.write(r["_raw"] + "\n")
                        else:
                            wf.write(json.dumps(r, ensure_ascii=False) + "\n")
                tmp.replace(LOG_FILE)

                st.success(f"å‰Šé™¤å®Œäº†: **{removed:,} è¡Œ** ã‚’å‰Šé™¤ / æ®‹ã‚Š {len(kept):,} è¡Œ")
                st.caption(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ: `{backup.name}`")

                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ– â†’ ãƒªãƒ­ãƒ¼ãƒ‰
                load_logs.clear()
                st.rerun()

            except Exception as e:
                st.error(f"å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
else:
    st.caption("å‰Šé™¤ã™ã‚‹å¹´æœˆã‚’é¸ã¶ã¨å®Ÿè¡Œãƒœã‚¿ãƒ³ãŒç¾ã‚Œã¾ã™ã€‚")



# ============================================================
# çµ‚äº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
# ============================================================
st.info(f"âœ… ç®¡ç†è€… {user} ã¨ã—ã¦é–²è¦§ä¸­ã€‚")
